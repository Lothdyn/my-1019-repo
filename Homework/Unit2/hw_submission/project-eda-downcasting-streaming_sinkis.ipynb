{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 2:  Homework Option III -- Working With Large Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework provides students with the option to get practice opening, sampling, and cleaning data when it has file sizes that might stretch your available RAM, or even exceed it.  \n",
    "\n",
    "**What you'll turn in:**\n",
    "\n",
    "You'll make a pull request with a folder (titled as your name) that contains the following:\n",
    "\n",
    " - for section I, a file called `titanic`, stored in a binary `feather` or `parquet` file format, that reduces the `titanic` dataset to its smallest possible memory amount without tampering any of its values.\n",
    " - for section II, simply turn in this notebook with the questions answered.\n",
    " - for section III, a script called `chunking.py` that, when run, will connect to an s3 bucket, and stream a file through memory, clean it, and output it to a `.csv` file, even though the entire file was never entirely loaded into RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I: Downcasting the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What You'll Learn:** The basics of managing memory within files, and how to use advanced file formats such as the `feather` or `parquet`, to make it easier to maintain persistent data types when a file isn't loaded.\n",
    "\n",
    "**What You'll Turn In:** A file called `titanic`, which contains the memory-reduced form of the file.\n",
    "\n",
    "#### Downcasting\n",
    "\n",
    "`Downcasting` is the task of reducing the memory footprint of different columns in your dataset so they take up less RAM when you load them in.  \n",
    "\n",
    "Most software used for handling data makes use of your available RAM to process its tasks.  If the size of your file neatly fits into the available RAM that your computer has then this is fine.  If it's significantly larger (no laptop is going to have 1TB of RAM for example), then you won't be able to load in the file and work with it.\n",
    "\n",
    "Pandas works this way, and therefore the amount of working RAM you have available to use is going to function as a limit for what file sizes you can work with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Quick Intro to Data Types in Pandas & Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers come in different flavors in pandas and numpy.  At the simplest level you have integers (whole numbers) and floating point numbers (numbers with decimals).  \n",
    "\n",
    "However, numbers use different sized containers to store their values.  They are as follows:\n",
    "\n",
    " - **64 bit:** Can store values as large as 2<sup>64</sup>, which is 18446744073709551616\n",
    " - **32 bit:** Can store values as large as 2<sup>32</sup>, which is 4294967296\n",
    " - **16 bit:** Good for values up to 2<sup>16</sup>, 65536\n",
    " - **8 bit:**  2<sup>8</sup>, or up to 264\n",
    " \n",
    "**Integers** typically have the above range, while **floats** typically can only go down to 32 bits.\n",
    "\n",
    "You can see the whole range of numeric data types here:  https://docs.scipy.org/doc/numpy/user/basics.types.html\n",
    "\n",
    "The important detail here, is that if a number is encoded as being a 64 bit number, it will *always* use the same amount of memory to store it, even if the value itself is much smaller.  \n",
    "\n",
    "So, if you have a column of 0's and 1's, an 8 bit encoding will work perfectly fine (since the values are less than 2<sup>8</sup>), and a 64 bit encoding will take up 8x as much memory as it needs to.\n",
    "\n",
    "An important detail about how Pandas works is that *all numbers are automatically encoded as 64 bit numbers*.  This is good for making sure values aren't tampered with, but bad for optimizing memory with large files.\n",
    "\n",
    "**Methods Used For Managing Memory In Pandas:**\n",
    "\n",
    " - `df.memory_usage()`, returns the memory usage, in bytes, of whatever is selected.\n",
    " - `pd.Series.astype()`, allows you to change the data type of 1 variable to another.\n",
    " - `df.info()`, returns the data type and memory usage of every column selected\n",
    " - `df.dtypes()/pd.Series.dtype()`, returns the data type of everything selected\n",
    " \n",
    "Let's take a look at how these items work.  Run the following cells to get a quick demonstration of what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start setting keys..\r\n",
      "Keys set.\r\n",
      "/Users/PRSmb/OneDrive/General-Assembly/my-1019-repo/Homework/Unit2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Templates configuration\n",
       "-----------------------\n",
       "    Default template: 'plotly'\n",
       "    Available templates:\n",
       "        ['ggplot2', 'seaborn', 'simple_white', 'plotly',\n",
       "         'plotly_white', 'plotly_dark', 'presentation', 'xgridoff',\n",
       "         'ygridoff', 'gridon', 'none']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the titanic dataset here -- use a different url if need be to\n",
    "# load it in\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "df = pd.read_csv('./data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the info of your dataset -- notice the 64 bit numbers\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index           128\n",
       "PassengerId    7128\n",
       "Survived       7128\n",
       "Pclass         7128\n",
       "Name           7128\n",
       "Sex            7128\n",
       "Age            7128\n",
       "SibSp          7128\n",
       "Parch          7128\n",
       "Ticket         7128\n",
       "Fare           7128\n",
       "Cabin          7128\n",
       "Embarked       7128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also check the memory usage of each column\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85664"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's see what happens when we adjust a columns data type\n",
    "df['Survived'].astype(np.int8).memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, an 8 bit number takes up about 1/8 as much memory as a 64 bit number.  Permanently changing something's data type is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will change the data type of a column to something else\n",
    "df['Survived'] = df['Survived'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index           128\n",
       "PassengerId    7128\n",
       "Survived        891\n",
       "Pclass         7128\n",
       "Name           7128\n",
       "Sex            7128\n",
       "Age            7128\n",
       "SibSp          7128\n",
       "Parch          7128\n",
       "Ticket         7128\n",
       "Fare           7128\n",
       "Cabin          7128\n",
       "Embarked       7128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now we can see its memory footprint is permanently smaller\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice however, that if you make a columns data type *smaller* than what it is, the original values will be tampered.  For example, the Passenger ID column has values as large as 891.....which is more than 2<sup>8</sup>.  Notice what happens when you make the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        3\n",
       "3        4\n",
       "4        5\n",
       "      ... \n",
       "886    119\n",
       "887    120\n",
       "888    121\n",
       "889    122\n",
       "890    123\n",
       "Name: PassengerId, Length: 891, dtype: int8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the values at the end of the series should be 889, 890, 891, etc\n",
    "df['PassengerId'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So clearly, getting things 'just right' is important.  Notice also the difference between **signed** and **unsigned** data types.  If it's signed, that means they can accept negative values.  \n",
    "\n",
    "So, a datatype of `np.uint8` can accept ranges of 0 - 255, whereas `np.int8` accepts values from -128 to 127."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Categorical Data in Pandas and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text based data in Pandas and Numpy has two different varieties:\n",
    "\n",
    " - **np.object**: this is the default numpy way of treating and handling data.  Pretty close to a python string, and is used to store data that doesn't have any other characteristic (integer, float, bool, etc)\n",
    " - **category**: this is a special data type built specifically for Pandas, to handle text data that has a small number of repeating values.  Like the `sex` column in our dataset.  When appropriately used, it can drastically reduce the memory footprint of text based data.  You can read more about them here:  https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    " \n",
    "See below for a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7256"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Sex column currently uses the same memory as a 64 bit number\n",
    "df['Sex'].memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you change it to a category, it uses about the same amount\n",
    "# as an 8 bit number\n",
    "df['Sex'].astype('category').memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that using categories only has the desired effect when there are repeating values.  Make sure to check the memory footprint before making the change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section I Task:  Clean Up the Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first part of your homework assignment, your task is to reduce the memory footprint of the titanic dataset as much as possible, while not tampering any values, and export it to a binary file format called `feather`(preferably), or `parquet` which will maintain information about all of its data types when it's loaded back in. \n",
    "\n",
    "You can read more about the feather file format here:  https://blog.rstudio.com/2016/03/29/feather/.\n",
    "\n",
    "The file `titanic` should be turned in inside a folder with your name on it, and it will be inspected to make sure it was downcasted in the most appropriate manner.\n",
    "\n",
    "You can use the `to_feather()`, and `read_feather()` methods to load and export your files.  Or the `to_parquet()` and `read_parquet()` methods, respectively.\n",
    "\n",
    "**Note:** It is best to use feather files if you can.  They are the only file format that can maintain persistent information about the `category` data type after it's been saved.\n",
    "\n",
    "However, you will likely need some additional libraries to get it working.  Often pandas does not work well with `feather` files right out of the box.  The typical library used to work with feather files is, appropriately called......feather.  To install the `feather` library, simply go to Anaconda Prompt/Terminal and type in `conda install feather-format`.\n",
    "\n",
    "The library's homepage can be found here:  https://pypi.org/project/feather-format/\n",
    "\n",
    "This library isn't always well supported, and there's a possibility that you might have an exceedingly difficult time getting it to work.  The purpose of this homework is not to have you go down rabbit holes getting an obscure library to work.  If after 30 minutes - 1 hour you still don't have the file installed, feel free to use the `parquet` file format, which can be a little easier to work with.\n",
    "\n",
    "You can find more about it here:  https://arrow.apache.org/docs/python/parquet.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 (1 of 2) - Reduce file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int8   \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(4), int8(1), object(5)\n",
      "memory usage: 77.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Starting point\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index           128\n",
       "PassengerId    7128\n",
       "Survived        891\n",
       "Pclass         7128\n",
       "Name           7128\n",
       "Sex            7128\n",
       "Age            7128\n",
       "SibSp          7128\n",
       "Parch          7128\n",
       "Ticket         7128\n",
       "Fare           7128\n",
       "Cabin          7128\n",
       "Embarked       7128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min and max value of each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                         0\n",
       "Pclass                           1\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                         female\n",
       "Age                           0.42\n",
       "SibSp                            0\n",
       "Parch                            0\n",
       "Ticket                      110152\n",
       "Fare                             0\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                            891\n",
       "Survived                                 1\n",
       "Pclass                                   3\n",
       "Name           van Melkebeke, Mr. Philemon\n",
       "Sex                                   male\n",
       "Age                                     80\n",
       "SibSp                                    8\n",
       "Parch                                    6\n",
       "Ticket                           WE/P 5735\n",
       "Fare                               512.329\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on workings:**\n",
    "* PassengerId 1-891 => np.int16\n",
    "\n",
    "* Survivied 0-1 => np.bool_\n",
    "\n",
    "* Pclass 1-3 => Test category or int8; use smaller\n",
    "\n",
    "* Name => This is text so don't mess with it as yet\n",
    "\n",
    "* Sex | check all values likely 'male','female' => Male or Female, test category, or boolean (since could deefine as male_flag without losing info, but potentially losing .\n",
    "\n",
    "* SibSp 0 - 8 => Likely repeating values, => test with category but probably int8\n",
    "\n",
    "* Age 0 - 80 => Likely repeating values, test with category but probably float16\n",
    "\n",
    "* Parch 0 - 6 => Likely repeating values, test with category but probably int8\n",
    "\n",
    "* Ticket => This is text so don't mess with it as yet\n",
    "\n",
    "* Fare 0 to 512.329 => Test with np.float16 (half precision float)\n",
    "\n",
    "* Cabin => Lots of text and nulls so no change\n",
    "\n",
    "* Embarked => Limited set of locations, so likely category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1910\n"
     ]
    }
   ],
   "source": [
    "a = df['PassengerId'].memory_usage()\n",
    "b = df['PassengerId'].astype(np.int16).memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 1019\n",
      "Reduced: 1019\n"
     ]
    }
   ],
   "source": [
    "a = df['Survived'].memory_usage()\n",
    "b = df['Survived'].astype(np.bool_).memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1019\n",
      "Reduced - Category: 1123\n"
     ]
    }
   ],
   "source": [
    "a = df['Pclass'].memory_usage()\n",
    "b = df['Pclass'].astype(np.int8).memory_usage()\n",
    "c = df['Pclass'].astype('category').memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}\\nReduced - Category: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1115\n"
     ]
    }
   ],
   "source": [
    "a = df['Sex'].memory_usage()\n",
    "b = df['Sex'].astype('category').memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['male_flag'] = (test_df['Sex']=='male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['male_flag'].memory_usage() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing a boolean flag of male / female would reduce memory usage beyond category by a further 96 bytes, but would force a change of data from the original data set and potentially reduce clarity. So won't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1019\n",
      "Reduced - Category: 1395\n"
     ]
    }
   ],
   "source": [
    "a = df['SibSp'].memory_usage()\n",
    "b = df['SibSp'].astype(np.int8).memory_usage()\n",
    "c = df['SibSp'].astype('category').memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}\\nReduced - Category: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df['Age'].memory_usage()\n",
    "b = df['Age'].astype(np.float16).memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df['Age'].memory_usage()\n",
    "b = df['Age'].astype(np.float16).memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age has nulls, so when try to use integers it fails\n",
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4813faf85648>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This produces errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df['Age'].astype(np.int8).memory_usage() # This produces errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1019\n",
      "Reduced - Category: 1395\n"
     ]
    }
   ],
   "source": [
    "a = df['Parch'].memory_usage()\n",
    "b = df['Parch'].astype(np.int8).memory_usage()\n",
    "c = df['Parch'].astype('category').memory_usage()\n",
    "print(f'Initial: {a}\\nReduced: {b}\\nReduced - Category: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1910\n"
     ]
    }
   ],
   "source": [
    "a = df['Fare'].memory_usage()\n",
    "b = df['Fare'].astype(np.float16).memory_usage()\n",
    "\n",
    "print(f'Initial: {a}\\nReduced: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: 7256\n",
      "Reduced: 1123\n"
     ]
    }
   ],
   "source": [
    "a = df['Embarked'].memory_usage()\n",
    "b = df['Embarked'].astype('category').memory_usage()\n",
    "\n",
    "print(f'Initial: {a}\\nReduced: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So best layout with new data types:\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PassengerId'] = df['PassengerId'].astype(np.int16)\n",
    "df['Survived'] = df['Survived'].astype(np.bool_)\n",
    "df['Pclass'] = df['Pclass'].astype(np.int8)\n",
    "df['Name'] = df['Name'].astype(str)\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['Age'] = df['Age'].astype(np.float16)\n",
    "df['SibSp'] = df['SibSp'].astype(np.int8)\n",
    "df['Parch'] = df['Parch'].astype(np.int8)\n",
    "df['Ticket'] = df['Ticket'].astype(str)\n",
    "df['Fare'] = df['Fare'].astype(np.float16)\n",
    "df['Cabin'] = df['Cabin'].astype(str)\n",
    "df['Embarked'] = df['Embarked'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index           128\n",
       "PassengerId    1782\n",
       "Survived        891\n",
       "Pclass          891\n",
       "Name           7128\n",
       "Sex             987\n",
       "Age            1782\n",
       "SibSp           891\n",
       "Parch           891\n",
       "Ticket         7128\n",
       "Fare           1782\n",
       "Cabin          7128\n",
       "Embarked        995\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  891 non-null    int16   \n",
      " 1   Survived     891 non-null    bool    \n",
      " 2   Pclass       891 non-null    int8    \n",
      " 3   Name         891 non-null    object  \n",
      " 4   Sex          891 non-null    category\n",
      " 5   Age          714 non-null    float16 \n",
      " 6   SibSp        891 non-null    int8    \n",
      " 7   Parch        891 non-null    int8    \n",
      " 8   Ticket       891 non-null    object  \n",
      " 9   Fare         891 non-null    float16 \n",
      " 10  Cabin        891 non-null    object  \n",
      " 11  Embarked     889 non-null    category\n",
      "dtypes: bool(1), category(2), float16(2), int16(1), int8(3), object(3)\n",
      "memory usage: 31.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32404"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So - in terms of adjusting data types, we were able to reduce memory from **85,664** to **32,404** within Pandas. This is a ~62% reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 (2 of 2) - Create Feather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses LZ4 by default\n",
    "feather.write_dataframe(df, './feather/titantic-f-default')\n",
    "\n",
    "# # Use LZ4 explicitly\n",
    "feather.write_dataframe(df, './feather/titantic-f-force-lz4', compression='lz4')\n",
    "\n",
    "# # Use ZSTD\n",
    "feather.write_dataframe(df, './feather/titantic-f-zstd', compression='zstd')\n",
    "\n",
    "# # Do not compress\n",
    "feather.write_dataframe(df, './feather/titantic-f-uncompressed', compression='uncompressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start setting keys..\r\n",
      "Keys set.\r\n",
      "/Users/PRSmb/OneDrive/General-Assembly/my-1019-repo/Homework/Unit2\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start setting keys..\r\n",
      "Keys set.\r\n",
      "total 376\r\n",
      "-rw-r--r--@ 1 PRSmb  staff    45K Nov 22 13:01 titantic-f-default\r\n",
      "-rw-r--r--@ 1 PRSmb  staff    45K Nov 22 13:01 titantic-f-force-lz4\r\n",
      "-rw-r--r--@ 1 PRSmb  staff    58K Nov 22 13:01 titantic-f-uncompressed\r\n",
      "-rw-r--r--@ 1 PRSmb  staff    31K Nov 22 13:01 titantic-f-zstd\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ./feather "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So smallest version of the file size (after reducing the file size) seems to be a 31 KB feather file, using zstd compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section II: Working With Larger File Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section I was your warmup to get the hang of how to reduce the memory of your data and get it loaded into a more advanced file format that can be reused for other projects.\n",
    "\n",
    "This section will extend what you just did, but add in two additional wrinkles:\n",
    "\n",
    " - The file will be much larger -- approximately 2 million rows\n",
    " - You'll find out what types of data types you should be working with.....*without* reading in the entire file in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine this hypothetical scenario:  there's a 10 gb file that you need to work on, and loading it into pandas is returning a `MemoryError`.  You're almost certain you could reduce it to something much smaller......except you can't even read it in to figure out what to do next.\n",
    "\n",
    "These types of chicken & egg problems are fairly common, and a popular antidote to them is to sample in a portion of your dataframe.  There are two primary ways to do this if you're reading in `.csv` files:\n",
    "\n",
    " - `nrows`   : tells you how many rows to read in from the original file\n",
    " - `skiprows`: tells you which rows to *skip* from the original file\n",
    " \n",
    "For both of these you can just manually read in x number of rows relatively easily, but doing so right from the beginning or end has some problems.  Mainly, many datasets don't have consistent values from beginning to end.  \n",
    "\n",
    "For example, if you have a dataset with 10 years of sales info, it's very possible values being recorded are very different at varying time segments.  Often new columns are added to datasets in the middle of their collection, and all values for all times before that are simply `null`, so just reading in the first 5000 or 10000 might not give you a consistent picture of what to expect.\n",
    "\n",
    "For this reason, it's good to randomly sample in dataframes before you want to read them in entirely.\n",
    "\n",
    "To do this, you can mix `lambda` functions (remember those?) with the `skiprows` argument, which can accept a function as values.\n",
    "\n",
    "Here's the basic idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# random.random() will generate a random value between 0 and 1\n",
    "# so this will return True 50% of the time\n",
    "random.random() > .50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49854\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for n in range(0,100000):\n",
    "    if random.random()>.50: i = i + 1\n",
    "        \n",
    "print(f\"{i/100000}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this same logic, we can pass this into a lambda function like so, to read in 30% of the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_csv with a lambda function\n",
    "df = pd.read_csv('./data/titanic.csv', skiprows=lambda x: x > 0 and random.random() > 0.3)\n",
    "# and notice the size of the dataframe that was read in\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, inside the `lambda` function, `x` represents the index value of the row being read in.  `x > 0` is used assuming the first row are headers, and of course `random.random() > 0.3` will return `True` 70% of the time, hence the results that we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that you can read in a very small fraction of a very large file if you want to investigate its most important properties.  \n",
    "\n",
    "Now, this begs the question.....how do you specify the data types you want a column to be before you read it in?  \n",
    "\n",
    "There is a very useful argument in `read_csv` called `dtype` that accepts a dictionary, where you can list column labels as keys, and their corresponding data type as a value.\n",
    "\n",
    "So for example, if we wanted to change the `Embarked` column and the `Survived` column to `category` and `np.int8`, we could do so in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary contains the columns we want to change\n",
    "dtypes = {\n",
    "    # column label: new data type\n",
    "    'Embarked': 'category',\n",
    "    'Survived': np.int8\n",
    "}\n",
    "\n",
    "# and now we'll re-read in the .csv file, and use the dtypes dict\n",
    "df = pd.read_csv('./data/titanic.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   PassengerId  891 non-null    int64   \n",
      " 1   Survived     891 non-null    int8    \n",
      " 2   Pclass       891 non-null    int64   \n",
      " 3   Name         891 non-null    object  \n",
      " 4   Sex          891 non-null    object  \n",
      " 5   Age          714 non-null    float64 \n",
      " 6   SibSp        891 non-null    int64   \n",
      " 7   Parch        891 non-null    int64   \n",
      " 8   Ticket       891 non-null    object  \n",
      " 9   Fare         891 non-null    float64 \n",
      " 10  Cabin        204 non-null    object  \n",
      " 11  Embarked     889 non-null    category\n",
      "dtypes: category(1), float64(2), int64(4), int8(1), object(4)\n",
      "memory usage: 71.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# and we can see that the data type of the columns are in fact changed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section II Task: Sample, Clean Up, And Read in the taxi.csv file\n",
    "\n",
    "This portion of section II contains the task that you will be graded on.  You can simply answer the prompts inside this notebook and turn it in.  No additional files are necessary.  The file is located in an S3 bucket at this location:  `https://dat-data.s3.amazonaws.com/taxi.csv`\n",
    "\n",
    "It records information about every taxi ride given by a particular company for approximately 1 year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part I:** Randomly sample in 10% the taxi.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual examination of the file shows taxi.csv has: \n",
    "* 1,710,671 rows\n",
    "* 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171333, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_csv with a lambda function\n",
    "df = pd.read_csv('./data/taxi.csv', skiprows=lambda x: x > 0 and random.random() > 0.1)\n",
    "# and notice the size of the dataframe that was read in\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 171333 entries, 0 to 171332\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   TRIP_ID       171333 non-null  int64  \n",
      " 1   CALL_TYPE     171333 non-null  object \n",
      " 2   ORIGIN_CALL   36687 non-null   float64\n",
      " 3   ORIGIN_STAND  80875 non-null   float64\n",
      " 4   TAXI_ID       171333 non-null  int64  \n",
      " 5   TIMESTAMP     171333 non-null  int64  \n",
      " 6   DAY_TYPE      171333 non-null  object \n",
      " 7   MISSING_DATA  171333 non-null  bool   \n",
      "dtypes: bool(1), float64(2), int64(3), object(2)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index               128\n",
       "TRIP_ID         1370664\n",
       "CALL_TYPE       1370664\n",
       "ORIGIN_CALL     1370664\n",
       "ORIGIN_STAND    1370664\n",
       "TAXI_ID         1370664\n",
       "TIMESTAMP       1370664\n",
       "DAY_TYPE        1370664\n",
       "MISSING_DATA     171333\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9766109"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we pulled in 10% of the file, we can assume that without modifying things the full file will be around 90mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part II:** Go ahead and do the appropriate exploratory data analysis to figure out the most appropriate data type for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372636965620000231</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000231</td>\n",
       "      <td>1372636965</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1372638481620000403</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20000403</td>\n",
       "      <td>1372638481</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372639875620000009</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000009</td>\n",
       "      <td>1372639875</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1372642178620000060</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000060</td>\n",
       "      <td>1372642178</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1372636896620000360</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000360</td>\n",
       "      <td>1372636896</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0  1372636965620000231         C          NaN           NaN  20000231   \n",
       "1  1372638481620000403         B          NaN          28.0  20000403   \n",
       "2  1372639875620000009         C          NaN           NaN  20000009   \n",
       "3  1372642178620000060         C          NaN           NaN  20000060   \n",
       "4  1372636896620000360         C          NaN           NaN  20000360   \n",
       "\n",
       "    TIMESTAMP DAY_TYPE  MISSING_DATA  \n",
       "0  1372636965        A         False  \n",
       "1  1372638481        A         False  \n",
       "2  1372639875        A         False  \n",
       "3  1372642178        A         False  \n",
       "4  1372636896        A         False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIP_ID              0\n",
       "CALL_TYPE            0\n",
       "ORIGIN_CALL     134646\n",
       "ORIGIN_STAND     90458\n",
       "TAXI_ID              0\n",
       "TIMESTAMP            0\n",
       "DAY_TYPE             0\n",
       "MISSING_DATA         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial observations** from looking at raw file, and header column\n",
    "\n",
    "* TRIP_ID - A very long long int\n",
    "* CALL_TYPE - Looks like some sort of category\n",
    "* ORIGIN_CALL - Lots of empty values, need to do some value checks but try category first\n",
    "* ORIGIN_STAND - Similar to origin_call\n",
    "* TAXI_ID - Looks like a long int\n",
    "* TIMESTAMP - Looks like a long int, not obviously a date time. Maybe it's already in UNIX logic?\n",
    "* DAY_TYPE - Looks like lots of repeated values\n",
    "* MISSING_DATA - Looks like it is boolean / lots of repeaated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIP_ID\t\tmax: 1404172754620000518\n",
      "CALL_TYPE\t\tmax: C\n",
      "ORIGIN_CALL\t\tmax: 63882.0\n",
      "ORIGIN_STAND\t\tmax: 63.0\n",
      "TAXI_ID\t\tmax: 20000969\n",
      "TIMESTAMP\t\tmax: 1404172754\n",
      "DAY_TYPE\t\tmax: A\n",
      "MISSING_DATA\t\tmax: False\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(f\"{c}\\t\\tmax: {df[c].max()}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Looking at max values** let's us make some quick decisions:\n",
    "\n",
    "\n",
    "* TRIP_ID - Super long - int64\n",
    "\n",
    "* CALL_TYPE - Looks like text, try Category\n",
    "\n",
    "* ORIGIN_CALL - Looks like it's a positive 5 digit number, but has nulls so needs to be a float, try float16\n",
    "\n",
    "\n",
    "* ORIGIN_STAND - Needs to be a float since there are nulls, try float 16\n",
    "\n",
    "\n",
    "* TAXI_ID - Looks like it's positive and 8 digits long, so uint32 since uint16 is too short at 5 digits.\n",
    "\n",
    "\n",
    "* TIMESTAMP - Looks like a long int, not obviously a date time. Maybe it's already in UNIX logic? 10 digits long, try uint32 (max of 4,294,967,295) given that the max here starts with 1.4*10^10; so unlikley other data starts at 4.2*10^10.\n",
    "\n",
    "\n",
    "* DAY_TYPE - Looks like lots of repeated values, try category\n",
    "\n",
    "\n",
    "* MISSING_DATA - Looks like it is boolean / lots of repeaated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:1370792\n"
     ]
    }
   ],
   "source": [
    "a = df['TRIP_ID'].memory_usage()\n",
    "b = df['TRIP_ID'].astype(np.int64).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:171565\n"
     ]
    }
   ],
   "source": [
    "a = df['CALL_TYPE'].memory_usage()\n",
    "b = df['CALL_TYPE'].astype('category').memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:342794\n"
     ]
    }
   ],
   "source": [
    "a = df['ORIGIN_CALL'].memory_usage()\n",
    "b = df['ORIGIN_CALL'].astype(np.float16).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:342794\n"
     ]
    }
   ],
   "source": [
    "a = df['ORIGIN_STAND'].memory_usage()\n",
    "b = df['ORIGIN_STAND'].astype(np.float16).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:342794\n"
     ]
    }
   ],
   "source": [
    "a = df['TAXI_ID'].memory_usage()\n",
    "b = df['TAXI_ID'].astype(np.float16).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:685460\n"
     ]
    }
   ],
   "source": [
    "a = df['TIMESTAMP'].memory_usage()\n",
    "b = df['TIMESTAMP'].astype(np.uint32).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:685460\n"
     ]
    }
   ],
   "source": [
    "a = df['TIMESTAMP'].memory_usage()\n",
    "b = df['TIMESTAMP'].astype(np.uint32).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:1370792 New:171549\n"
     ]
    }
   ],
   "source": [
    "a = df['DAY_TYPE'].memory_usage()\n",
    "b = df['DAY_TYPE'].astype('category').memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:171461 New:171461\n"
     ]
    }
   ],
   "source": [
    "a = df['MISSING_DATA'].memory_usage()\n",
    "b = df['MISSING_DATA'].astype(np.bool_).memory_usage()\n",
    "print(f\"Original:{a} New:{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part III**: Create a dictionary that contains the key/value pairs for each column that needs to be changed to a different data type, and then read in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.finfo(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - Decided to use all columns to ensure didn't miss anything\n",
    "dtypes_taxi = {\n",
    "    # column label: new data type\n",
    "    'TRIP_ID' : np.int64,\n",
    "    'CALL_TYPE' : 'category',\n",
    "    'ORIGIN_CALL' : np.float32, \n",
    "        # This causes an error set to np.uint16 due to base being a float\n",
    "        # So use float32 since max value seen was 63882 in sample, could go above 66k\n",
    "        # This is likely due to there being null / NaN values\n",
    "    'ORIGIN_STAND' : np.float16,\n",
    "        #This causes an error set to np.uint8 due to base being a float\n",
    "        # So use float16 since max value seen was 2 digit 63.0 well under 65k\n",
    "        # This is likely due to there being null / NaN values\n",
    "    'TAXI_ID' : np.uint32,\n",
    "    'TIMESTAMP' : np.uint32,\n",
    "    'DAY_TYPE' : 'category',\n",
    "    'MISSING_DATA' : np.bool_    ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRIP_ID': numpy.int64,\n",
       " 'CALL_TYPE': 'category',\n",
       " 'ORIGIN_CALL': numpy.float32,\n",
       " 'ORIGIN_STAND': numpy.float16,\n",
       " 'TAXI_ID': numpy.uint32,\n",
       " 'TIMESTAMP': numpy.uint32,\n",
       " 'DAY_TYPE': 'category',\n",
       " 'MISSING_DATA': numpy.bool_}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtypes_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_csv('./data/taxi.csv', dtype=dtypes_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1710670, 8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part IV:** Confirm that each column has the appropriate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710670 entries, 0 to 1710669\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Dtype   \n",
      "---  ------        -----   \n",
      " 0   TRIP_ID       int64   \n",
      " 1   CALL_TYPE     category\n",
      " 2   ORIGIN_CALL   float32 \n",
      " 3   ORIGIN_STAND  float16 \n",
      " 4   TAXI_ID       uint32  \n",
      " 5   TIMESTAMP     uint32  \n",
      " 6   DAY_TYPE      category\n",
      " 7   MISSING_DATA  bool    \n",
      "dtypes: bool(1), category(2), float16(1), float32(1), int64(1), uint32(2)\n",
      "memory usage: 40.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_taxi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                128\n",
       "TRIP_ID         13685360\n",
       "CALL_TYPE        1710774\n",
       "ORIGIN_CALL      6842680\n",
       "ORIGIN_STAND     3421340\n",
       "TAXI_ID          6842680\n",
       "TIMESTAMP        6842680\n",
       "DAY_TYPE         1710678\n",
       "MISSING_DATA     1710670\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42766990"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_taxi.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section III (Optional): File Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File streaming is a way to get around memory limitations in pandas.  When you stream in a file, you spoon feed a portion of it into memory, and when you're finished, load in the next portion, and so on until there's nothing left. \n",
    "\n",
    "It's less convenient than regular file I/O, but it removes any sort of memory limit you might face when working with a file because it's never loaded at the same time. \n",
    "\n",
    "In this section of the homework assignment, you'll be tasked with performing basic cleaning operations on a file......without ever having to load it into memory.  This means what you accomplish in this section you could perform on a file of any size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Introduction to File Streams\n",
    "\n",
    "When it's available, you can specify a file stream by using the `chunksize` argument, which specifies that you only read in so many lines at a time.\n",
    "\n",
    "Notice how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.io.parsers.TextFileReader"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when we read in the csv file, we'll set chunksize to 200\n",
    "df = pd.read_csv('./data/titanic.csv', chunksize=250)\n",
    "\n",
    "# notice that df is NOT a df.....it's a file stream\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Minahan, Dr. William Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19928</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>C78</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lindahl, Miss. Agda Thorilda Viktoria</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347071</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamalainen, Mrs. William (Anna)</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mr. Richard Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Carter, Rev. Ernest Courtenay</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>244252</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "245          246         0       1   \n",
       "246          247         0       3   \n",
       "247          248         1       2   \n",
       "248          249         1       1   \n",
       "249          250         0       2   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "245                        Minahan, Dr. William Edward    male  44.0      2   \n",
       "246              Lindahl, Miss. Agda Thorilda Viktoria  female  25.0      0   \n",
       "247                    Hamalainen, Mrs. William (Anna)  female  24.0      0   \n",
       "248                      Beckwith, Mr. Richard Leonard    male  37.0      1   \n",
       "249                      Carter, Rev. Ernest Courtenay    male  54.0      1   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "245      0             19928  90.0000   C78        Q  \n",
       "246      0            347071   7.7750   NaN        S  \n",
       "247      2            250649  14.5000   NaN        S  \n",
       "248      1             11751  52.5542   D35        S  \n",
       "249      0            244252  26.0000   NaN        S  \n",
       "\n",
       "[250 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now if we want, we can 'chunk' in 250 rows at a time\n",
    "df.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Reed, Mr. James George</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>362316</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Strom, Mrs. Wilhelm (Elna Matilda Persson)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stead, Mr. William Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113514</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C87</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lobb, Mr. William Arthur</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 3336</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rosblom, Mrs. Viktor (Helena Wilhelmina)</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>370129</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yousseff, Mr. Gerious</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Eustis, Miss. Elizabeth Mussey</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36947</td>\n",
       "      <td>78.2667</td>\n",
       "      <td>D20</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shellard, Mr. Frederick William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 6212</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350035</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "250          251         0       3   \n",
       "251          252         0       3   \n",
       "252          253         0       1   \n",
       "253          254         0       3   \n",
       "254          255         0       3   \n",
       "..           ...       ...     ...   \n",
       "495          496         0       3   \n",
       "496          497         1       1   \n",
       "497          498         0       3   \n",
       "498          499         0       1   \n",
       "499          500         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "250                           Reed, Mr. James George    male   NaN      0   \n",
       "251       Strom, Mrs. Wilhelm (Elna Matilda Persson)  female  29.0      1   \n",
       "252                        Stead, Mr. William Thomas    male  62.0      0   \n",
       "253                         Lobb, Mr. William Arthur    male  30.0      1   \n",
       "254         Rosblom, Mrs. Viktor (Helena Wilhelmina)  female  41.0      0   \n",
       "..                                               ...     ...   ...    ...   \n",
       "495                            Yousseff, Mr. Gerious    male   NaN      0   \n",
       "496                   Eustis, Miss. Elizabeth Mussey  female  54.0      1   \n",
       "497                  Shellard, Mr. Frederick William    male   NaN      0   \n",
       "498  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.0      1   \n",
       "499                               Svensson, Mr. Olof    male  24.0      0   \n",
       "\n",
       "     Parch     Ticket      Fare    Cabin Embarked  \n",
       "250      0     362316    7.2500      NaN        S  \n",
       "251      1     347054   10.4625       G6        S  \n",
       "252      0     113514   26.5500      C87        S  \n",
       "253      0  A/5. 3336   16.1000      NaN        S  \n",
       "254      2     370129   20.2125      NaN        S  \n",
       "..     ...        ...       ...      ...      ...  \n",
       "495      0       2627   14.4583      NaN        C  \n",
       "496      0      36947   78.2667      D20        C  \n",
       "497      0  C.A. 6212   15.1000      NaN        S  \n",
       "498      2     113781  151.5500  C22 C26        S  \n",
       "499      0     350035    7.7958      NaN        S  \n",
       "\n",
       "[250 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and this would be the next 250 rows\n",
    "df.get_chunk()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this basic syntax, you can lazily read in bits and pieces of a file at a time, without having to worry about being able to fit the entire file into RAM at once.  This is useful for doing some basic exploratory data analysis, and peek into a file, even if it's unreasonably large.\n",
    "\n",
    "However, what if you wanted some way to go through the *entire* file, and make bulk changes to it?  \n",
    "\n",
    "You can do that as well, by looping through the file stream. Here's a simple example, that prints off the total memory footprint for each chunk being read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19328\n",
      "19332\n",
      "19332\n",
      "19332\n",
      "8868\n"
     ]
    }
   ],
   "source": [
    "# this basically reads: for every chunk in the file stream\n",
    "for chunk in pd.read_csv('./data/titanic.csv', chunksize=200):\n",
    "    # do this to each chunk\n",
    "    print(chunk.memory_usage().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what we're doing here.  `chunk` is the portion of the file that you're reading in and operating on.  `pd.read_csv(.....)` in this case is the iterator that you're looping over, not the entire file itself.\n",
    "\n",
    "What's a little difficult to get used to is that `chunk` isn't some stand alone file that you play with once you've loaded it in.  It's just a portion of a loop that you pass some commands to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish this section of the homework, you'll need to write functions that allow you to stream in data, and perform specific operations on your data set, without having it entirely loaded into memory, or being able to see it.\n",
    "\n",
    "These functions should be written in a file called `chunking.py`, and each of the following two functions should be able to be called from an IDE to observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function 1**\n",
    "\n",
    "**Name:** `probe_df`\n",
    "\n",
    "**Arguments:** \n",
    " - `file_path`, str; required,  Location of file to read in.\n",
    " - `chunksize`, int, required, default value is 1000.  Size of the chunk to use when streaming in the file.\n",
    " \n",
    "**Returns:** a dictionary encoded in the following way: \n",
    " - each key is the name of a column within your dataset\n",
    " - the value for each key is another dictionary with the following key/value pairs:\n",
    "   - `null values`: number of null values for that column\n",
    "   - `dtype`: data type for that column\n",
    "   - `avg_val`: average value for that column ( if numeric, otherwise don't include )\n",
    "   \n",
    "**Note:** The `chunksize` argument can be used with a variety of file types, but you can just assume that you'll be reading a csv file, and nothing more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function II**\n",
    "\n",
    "**Name:** `write_df`\n",
    "\n",
    "**Arguments:**\n",
    "\n",
    " - `file_path_read`   : str, required; location of file to read in.\n",
    " - `file_path_write`  : str, required; location of the file to write the new file out to\n",
    " - `chunksize`, int, required, default value is 1000.  Size of the chunk to use when streaming in the file.\n",
    " - `missing_vals`: dict, optional; accepts a dictionary as an argument with key/value pairs that list the column in the dataset(key) as well as the value to fill missing values with for that column(value).  The values in this dictionary will be used to fill missing values in the file at the location in `file_path_read`.\n",
    " \n",
    "**Returns:**\n",
    "\n",
    "This function will **not** return a value in the terminal.  What it **will** do is write a new file to the location specified in `file_path_write`.  \n",
    "\n",
    "So, for example if you call `write_df('file/path/to/stream', 'file/path/to/write')`, a new file will appear in the location at `file/path/to/write` as the function is being called.\n",
    "\n",
    "The big idea behind this file is that you'll be able to do data cleaning operations on a file you've never actually seen in your terminal before.\n",
    "\n",
    "**Hint:** Pandas has a `to_csv()` method, with the option of appending lines to the end of it -- this is good to use when looping through the file stream.\n",
    "\n",
    "**Note:** We will check to see that column headers are not added multiple times!\n",
    "\n",
    "**To Test:** We will first call `probe_df` on the `taxi` dataset in its original location to get a dictionary with its missing values.  We will then use that value as a basis for the `missing_vals` argument in the `write_df` function, and use those to fill in its missing values.\n",
    "\n",
    "If both of these functions work as intended, they will allow us to fill in the dataset's missing values without having looked at it, and you will receive full marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
